<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>
      Svaraikyam Research & Prototypes Lab (SRPL) | Independent Applied Research
      and Prototypes
    </title>
    <!-- Tailwind CSS -->
    <script src="https://cdn.tailwindcss.com"></script>
    <!-- Google Fonts: Inter -->
    <link rel="preconnect" href="https://fonts.googleapis.com" />
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
    <link
      href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700;800&display=swap"
      rel="stylesheet"
    />
    <!-- Font Awesome for Icons -->
    <link
      rel="stylesheet"
      href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.1.1/css/all.min.css"
    />

    <!-- FIREBASE SDK IMPORTS  -->
    <script type="module">
      import { initializeApp } from "https://www.gstatic.com/firebasejs/12.6.0/firebase-app.js";
      import {
        getAuth,
        signInAnonymously,
        signInWithCustomToken,
        onAuthStateChanged,
      } from "https://www.gstatic.com/firebasejs/12.6.0/firebase-auth.js";
      import {
        getFirestore,
        doc,
        getDoc,
        updateDoc,
        setDoc,
        increment,
        onSnapshot,
      } from "https://www.gstatic.com/firebasejs/12.6.0/firebase-firestore.js";
      
      // We will define a minimal setLogLevel if it's not available in the environment scope
      const setLogLevel = console.log;

      // --- CONFIGURATION LOADING ---
      // Hardcoded config is used as a fallback if the environment variables are not present.
      const hardcodedConfig = {
        // NOTE: API Key is now assumed to be supplied correctly by the user/environment
        apiKey: "AIzaSyAtc4tGXWIhPRnCcSZY_Zf7030RcjaZ2zA", 
        authDomain: "svaraikyam-labs.firebaseapp.com",
        projectId: "svaraikyam-labs",
        storageBucket: "svaraikyam-labs.firebasestorage.app",
        messagingSenderId: "914020808014",
        appId: "1:914020808014:web:8f2c5dc99dbb240e5a5a1f",
        measurementId: "G-MJYY25HCRB",
      };

      const firebaseConfig =
        typeof __firebase_config !== "undefined"
          ? JSON.parse(__firebase_config)
          : hardcodedConfig;

      const envAppId =
        typeof __app_id !== "undefined" ? __app_id : firebaseConfig.projectId;
      const initialAuthToken =
        typeof __initial_auth_token !== "undefined"
          ? __initial_auth_token
          : null;
      // -----------------------------

      const appId = envAppId || "default-app-id";

      let app, db, auth;
      // We only keep the global counter element
      const globalCounterElement = document.getElementById("visitor-counter");


      if (!firebaseConfig.apiKey) {
        console.error(
          "Firebase configuration is missing. The visitor counter will not function."
        );
        globalCounterElement.textContent = "Config Error";
      }

      // Initialize Firebase App and Services (using the environment or hardcoded config)
      try {
        app = initializeApp(firebaseConfig);
        db = getFirestore(app);
        auth = getAuth(app);
        setLogLevel("error"); // Set log level to 'error' to minimize console noise
        console.log("Firebase Initialized.");
      } catch (e) {
        console.error(
          "Could not initialize Firebase. Counter functionality will be unavailable.",
          e
        );
        globalCounterElement.textContent = "DB Error";
        // Set db and auth to null to prevent errors in subsequent functions
        db = null;
        auth = null;
      }

      // Define Firestore Paths using the Canvas Environment standard
      // Public Counter Path: /artifacts/{appId}/public/data/site_data/total_unique_visitors
      const GLOBAL_COUNTER_DOC_PATH = `site_data/total_unique_visitors`;

      // 2. Unique User Tracking: CHANGED to match a short path: /user_visits/{userId}
      function getPublicUserVisitDocRef(userId) {
        if (!db) return null;
        return doc(
          db,
          "user_visits", // Short collection name
          userId
        );
      }

      const GLOBAL_COUNTER_DOC_REF = db
        ? doc(db, GLOBAL_COUNTER_DOC_PATH)
        : null;

      // Use exponential backoff for retries
      const MAX_RETRIES = 5;
      const initialDelay = 1000; // 1 second

      async function attemptFetch(operation, ...args) {
        for (let i = 0; i < MAX_RETRIES; i++) {
          try {
            return await operation(...args);
          } catch (error) {
            // Only retry on network errors or transient backend issues
            if (
              error.code &&
              (error.code === "unavailable" || error.code === "internal")
            ) {
              const delay =
                initialDelay * Math.pow(2, i) + Math.random() * 1000;
              await new Promise((resolve) => setTimeout(resolve, delay));
            } else {
              throw error; // Re-throw non-retryable errors
            }
          }
        }
        throw new Error("Max retries reached.");
      }

      async function updateVisitorCounter(user) {
        if (!db || !GLOBAL_COUNTER_DOC_REF) return; // Guard against uninitialized DB/Refs

        const userId = user.uid;
        const userVisitDocRef = getPublicUserVisitDocRef(userId);

        if (!userVisitDocRef) return;

        try {
          // 1. Check if this user has ever been counted as a UNIQUE visitor
          const visitSnapshot = await attemptFetch(getDoc, userVisitDocRef);
          const hasVisitedBefore = visitSnapshot.exists();

          if (!hasVisitedBefore) {
            // A. NEW UNIQUE USER: Increment Global Counter and Initialize User's Visit Doc

            // 1. Mark user as visited in the public user_visits collection
            await attemptFetch(setDoc, userVisitDocRef, {
              visitedAt: new Date().toISOString(),
            });

            // 2. Increment the global unique counter
            await attemptFetch(updateDoc, GLOBAL_COUNTER_DOC_REF, {
              count: increment(1),
            });
            console.log(`[${userId.substring(0, 8)}] NEW UNIQUE VISITOR! Global count incremented.`);
          } else {
            console.log(`[${userId.substring(0, 8)}] Returning visitor. Global count not incremented.`);
          }

        } catch (error) {
          // Handle the initial creation of the global counter document gracefully.
          if (
            error.code === "not-found" &&
            error.message.includes(GLOBAL_COUNTER_DOC_REF.path)
          ) {
            // Attempt to create the GLOBAL document with initial count 1 (only if it truly doesn't exist)
            try {
              console.log("Global counter document not found. Creating it with count: 1.");
              await attemptFetch(setDoc, GLOBAL_COUNTER_DOC_REF, { count: 1 });
            } catch (e) {
              console.error(
                "Error setting initial global counter document:",
                e
              );
            }
          } else {
             console.error("Error updating unique visitor counter logic:", error);
          }
         
        }
      }

      function displayCurrentCount(count) {
        if (globalCounterElement) {
          globalCounterElement.textContent = count.toLocaleString("en-US");
        }
      }

      function listenForGlobalCountChanges() {
        if (!db || !GLOBAL_COUNTER_DOC_REF) return; // Guard against uninitialized DB/Refs

        // Using onSnapshot for real-time updates of the total unique count
        onSnapshot(
          GLOBAL_COUNTER_DOC_REF,
          (docSnapshot) => {
            if (docSnapshot.exists()) {
              const data = docSnapshot.data();
              // The public count field is named 'count'
              displayCurrentCount(data.count || 0);
            } else {
              displayCurrentCount(0); // If the document doesn't exist yet
            }
          },
          (error) => {
            console.error("Error fetching real-time total count:", error);
            displayCurrentCount("Err");
          }
        );
      }

      // --- INITIALIZATION AND AUTHENTICATION ---
      async function initAuthAndCounters() {
        if (!db || !auth) return;

        // 1. Start listening for the public global UNIQUE count immediately
        listenForGlobalCountChanges();

        // Set initial state
        globalCounterElement.textContent = "...";

        // 2. Attempt Sign In (prefer custom token, fall back to anonymous)
        try {
          if (initialAuthToken) {
            await signInWithCustomToken(auth, initialAuthToken);
          } else {
            await signInAnonymously(auth);
          }
        } catch (error) {
          console.error("Error during initial sign-in attempt:", error);
        }

        // 3. Listen for Auth State Change to execute counter logic
        onAuthStateChanged(auth, async (user) => {
          if (user) {
            // User is authenticated
            // Run the logic to check and increment the global unique count
            await updateVisitorCounter(user);
          } else {
            console.log("Authentication failed or user signed out.");
          }
        });
      }

      initAuthAndCounters();
    </script>
    <style>
      /* Custom styles for the page */
      body {
        font-family: "Inter", sans-serif;
        background-color: #0f172a; /* slate-900 */
        color: #f8fafc; /* slate-50 */
        scroll-behavior: smooth;
      }
      .section-title {
        font-size: 2.5rem;
        font-weight: 700;
        color: #ffffff;
        text-align: center;
        margin-bottom: 1rem;
      }
      .section-subtitle {
        font-size: 1.25rem;
        color: #94a3b8; /* slate-400 */
        text-align: center;
        margin-bottom: 3rem;
        max-width: 600px;
        margin-left: auto;
        margin-right: auto;
      }
      .content-card {
        background-color: #1e293b; /* slate-800 */
        padding: 1.5rem;
        border-radius: 0.75rem;
        box-shadow: 0 10px 15px rgba(0, 0, 0, 0.2);
        transition: transform 0.3s, box-shadow 0.3s;
        border: 1px solid #334155; /* slate-700 */
        display: flex;
        flex-direction: column;
      }
      .content-card:hover {
        transform: translateY(-5px);
        box-shadow: 0 15px 25px rgba(0, 0, 0, 0.3);
      }
      /* Custom video style for responsiveness */
      .responsive-media-container {
        position: relative;
        padding-bottom: 56.25%; /* 16:9 aspect ratio */
        height: 0;
        overflow: hidden;
        border-radius: 0.5rem;
        background-color: #0f172a;
      }
      .responsive-media-container video,
      .responsive-media-container img,
      .responsive-media-container iframe {
        /* Added iframe for embeds */
        position: absolute;
        top: 0;
        left: 0;
        width: 100%;
        height: 100%;
        object-fit: cover;
      }
      /* Style for the CTA button on Research Focus Section */
      .cta-button {
        display: inline-flex;
        align-items: center;
        justify-content: center;
        padding: 0.75rem 1.5rem;
        border-radius: 0.5rem;
        font-weight: 600;
        transition: all 0.3s;
        box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
      }
      .cta-button-primary {
        background-color: #0ea5e9; /* sky-500 */
        color: #ffffff;
      }
      .cta-button-primary:hover {
        background-color: #0284c7; /* sky-600 */
        transform: translateY(-2px);
      }
      .cta-button-secondary {
        background-color: #475569; /* slate-600 */
        color: #ffffff;
      }
      .cta-button-secondary:hover {
        background-color: #334155; /* slate-700 */
        transform: translateY(-2px);
      }
    </style>
  </head>
  <body>
    <!-- Header/Navigation -->
    <header class="bg-slate-900 border-b border-slate-800 sticky top-0 z-10">
      <nav
        class="container mx-auto px-6 py-4 flex justify-between items-center"
      >
        <!-- Logo/Brand -->
        <a href="index.html" class="flex items-center space-x-2">
          <!-- Placeholder logo for Svaraikyam AI -->
          <img
            src="company_logo.png"
            alt="Svaraikyam AI Logo"
            class="h-8 w-auto rounded"
            onerror="this.onerror=null; this.src='https://placehold.co/40x32/e6f2ff/007bff?text=AI';"
          />
          <span class="text-xl font-bold text-white"
            >Svaraikyam Research & Prototypes Lab (<span class="text-sky-400"
              >SRPL</span
            >)</span
          >
        </a>
        <!-- Navigation Links -->
        <ul class="flex space-x-6">
          <li>
            <a
              href="index.html"
              class="text-sky-400 font-semibold hover:text-white transition-colors"
              >Home</a
            >
          </li>
          <li>
            <a
              href="products.html"
              class="text-slate-300 hover:text-white transition-colors"
              >Products</a
            >
          </li>
          <li>
            <a
              href="embedded-ai-trainings.html"
              class="text-slate-300 hover:text-white transition-colors"
              >Trainings</a
            >
          </li>
          <li>
            <a
              href="about-contact.html"
              class="text-slate-300 hover:text-white transition-colors"
              >About & Contact</a
            >
          </li>
        </ul>
      </nav>
    </header>

    <main>
      <!-- Hero Section - Svaraikyam Research Lab -->
      <section id="research-intro" class="py-20 text-center bg-slate-900">
        <div class="container mx-auto px-6">
          <h1 class="text-5xl md:text-6xl font-extrabold mb-4 text-white">
            <span class="text-sky-400"
              >Svaraikyam Research & Prototypes Lab (SRPL)</span
            >
          </h1>
          <h2 class="text-4xl font-extrabold mb-4 text-white">
            Pioneering Edge AI ,GPU & Robotics Solutions
          </h2>
          <p class="text-xl text-slate-300 mb-8 max-w-4xl mx-auto">
            An independent applied research initiative focused on solving
            real-world challenges through GPU-HPC, AI Model Engineering, and
            Robotics Research & Prototypes.
          </p>
          <a
            href="about-contact.html"
            class="bg-sky-500 hover:bg-sky-600 text-white cta-button"
            >Contact us for Collaboration & Consultancy &rarr;</a
          >
        </div>
      </section>

      <!-- The AI & Robotics Lab Section -->
      <section id="ai-lab" class="py-16">
        <div class="container mx-auto px-6">
          <div
            class="grid md:grid-cols-2 gap-12 items-center bg-slate-800 p-8 rounded-xl shadow-2xl"
          >
            <!-- Text Content -->
            <div class="md:order-1">
              <h3 class="text-3xl font-bold text-sky-400 mb-4">
                The AI & Robotics Lab: Our R&D Core
              </h3>
              <p class="text-lg text-slate-300 mb-4">
                Our AI & Robotics Lab is equipped with advanced edge-computing
                platforms including
                <strong class="text-white">Qualcomm RB3 Gen2</strong>,
                <strong class="text-white">RB5</strong>, and
                <strong class="text-white">NVIDIA Jetson Orin</strong> systems.
                We use these platforms to design, develop, and optimize
                real-time robotics workloads such as perception, navigation,
                mapping, and sensor fusion.
              </p>
              <a
                href="ai-lab-details.html"
                class="text-sky-400 font-semibold text-lg hover:underline"
                >Discover Our Lab &rarr;</a
              >
            </div>
            <!-- Image/Media -->
            <div class="md:order-2">
              <!-- Placeholder for 'lab.png' -->
              <img
                src="lab.png"
                alt="AI Robotics Lab Equipment"
                class="rounded-xl shadow-lg w-full h-auto"
                onerror="this.onerror=null; this.src='https://placehold.co/600x400/1e293b/ffffff?text=AI+Lab+Image';"
              />
            </div>
          </div>
        </div>
      </section>

      <!-- Featured Research Projects Section (12 Total) -->
      <section id="research-projects" class="py-16 bg-slate-800">
        <div class="container mx-auto px-6">
          <h2 class="section-title text-center text-sky-400 mb-1">
            Our Featured Research Projects & Prototypes (<span
              class="text-white"
              >12 Total</span
            >)
          </h2>
          <p class="section-subtitle">
            A glance at our most ambitious and challenging applied research
            initiatives, covering Edge AI, CV, GPU optimization, and LLMs.
          </p>

          <!-- Projects Grid (3x4 Layout for 12 items) -->
          <div class="grid grid-cols-1 md:grid-cols-2 lg:grid-cols-3 gap-8">
            <!-- Project 1: GPU Acceleration for Visual Search, Retrieval, and Detection (Original) -->
            <div class="content-card">
              <div class="responsive-media-container mb-4">
                <!-- Placeholder for find_obj.png -->
                <img
                  src="find_obj.png"
                  alt="Visual Search GPU Acceleration"
                  class="rounded-lg shadow-md w-full h-full object-cover"
                  onerror="this.onerror=null; this.src='https://placehold.co/600x337/1e293b/ffffff?text=Project+1+GPU+Search';"
                />
              </div>
              <h4 class="text-xl font-bold text-sky-400 mb-2">
                1. GPU Acceleration for Visual Search, Retrieval, and Detection
              </h4>
              <p class="text-slate-300 text-sm flex-grow">
                High-performance implementation of visual search and object
                detection pipelines, heavily optimized using GPU acceleration
                (CUDA/OpenCL) for massive-scale, real-time image retrieval and
                analysis.
              </p>
              <a
                href="https://github.com/intelav/GeoAccel-AI"
                target="_blank"
                class="text-sky-400 font-semibold text-sm mt-3 inline-block hover:underline"
                >View on GitHub &rarr;</a
              >
            </div>

            <!-- Project 2: Agentic Compute on GPU (Original) -->
            <div class="content-card">
              <div class="responsive-media-container mb-4">
                <img
                  src="nsight.png"
                  alt="Agentic Compute on GPU"
                  class="rounded-lg shadow-md w-full h-full object-cover"
                  onerror="this.onerror=null; this.src='https://placehold.co/600x337/334155/e2e8f0?text=Project+2+Agentic+Compute';"
                />
              </div>
              <h4 class="text-xl font-bold text-sky-400 mb-2">
                2. Agentic Compute on GPU
              </h4>
              <p class="text-slate-300 text-sm flex-grow">
                Research into parallelizing sophisticated AI agent workflows and
                decision-making loops directly on the GPU, maximizing throughput
                for complex, multi-step computational tasks.
              </p>
              <div class="mt-3 text-sm space-y-1">
                <a
                  href="https://test.pypi.org/project/gpu-agent-opt"
                  target="_blank"
                  class="text-sky-400 font-semibold inline-block hover:underline"
                  >PyPI Link &rarr;</a
                >
                <span class="text-slate-500">|</span>
                <a
                  href="https://github.com/intelav/gpu-agent-opt"
                  target="_blank"
                  class="text-sky-400 font-semibold inline-block hover:underline"
                  >GitHub &rarr;</a
                >
              </div>
            </div>

            <!-- Project 3: NEW - Softmax Benchmarking on RTX GPU -->
            <div class="content-card">
              <div class="responsive-media-container mb-4">
                <img
                  src="softmax.png"
                  alt="Softmax Benchmarking on RTX GPU"
                  class="rounded-lg shadow-md w-full h-full object-cover"
                />
              </div>
              <h4 class="text-xl font-bold text-sky-400 mb-2">
                3. Softmax Benchmarking on RTX GPU
              </h4>
              <p class="text-slate-300 text-sm flex-grow">
                Detailed performance analysis and optimization of various
                Softmax kernel implementations for NVIDIA RTX GPUs, focusing on
                CUDA performance for machine learning layers.
              </p>
              <a
                href="https://github.com/intelav/cuda-softmax-bench"
                target="_blank"
                class="text-sky-400 font-semibold text-sm mt-3 inline-block hover:underline"
                >View on GitHub &rarr;</a
              >
            </div>

            <!-- Project 4: NEW - GEMM Benchmarking on RTX GPU -->
            <div class="content-card">
              <div class="responsive-media-container mb-4">
                <img
                  src="gemm.png"
                  alt="GEMM Benchmarking on RTX GPU"
                  class="rounded-lg shadow-md w-full h-full object-cover"
                />
              </div>
              <h4 class="text-xl font-bold text-sky-400 mb-2">
                4. GEMM Benchmarking on RTX GPU
              </h4>
              <p class="text-slate-300 text-sm flex-grow">
                General Matrix Multiply (GEMM) performance investigation on RTX
                GPUs, utilizing CUDA Tensor Cores for highly accelerated linear
                algebra operations critical for deep learning inference.
              </p>
              <a
                href="embedded_research.html"
                class="text-sky-400 font-semibold text-sm mt-3 inline-block hover:underline"
                >Explore Research &rarr;</a
              >
            </div>

            <!-- Project 5: NEW - Satellite Change Detection using Change Star on Copernicus Dataset -->
            <div class="content-card">
              <div class="responsive-media-container mb-4">
                <img
                  src="chgdet.png"
                  alt="Satellite Change Detection"
                  class="rounded-lg shadow-md w-full h-full object-cover"
                />
              </div>
              <h4 class="text-xl font-bold text-sky-400 mb-2">
                5. Satellite Change Detection using Change Star on Copernicus
                Dataset
              </h4>
              <p class="text-slate-300 text-sm flex-grow">
                Applied research in detecting land cover changes using the
                ChangeStar model, fine-tuned and evaluated on the
                high-resolution Copernicus Sentinel-2 satellite imagery.
              </p>
              <a
                href="https://github.com/intelav/SentinelChange-AI"
                target="_blank"
                class="text-sky-400 font-semibold text-sm mt-3 inline-block hover:underline"
                >View on GitHub &rarr;</a
              >
            </div>

            <!-- Project 6: SHIFTED - Voice LLM on Jetson Orin (Original Project 3) -->
            <div class="content-card">
              <div class="responsive-media-container mb-4">
                <!-- Original Project 3 Video -->
                <video
                  src="voice_llm_demo.mp4"
                  autoplay
                  loop
                  muted
                  playsinline
                  class="rounded-lg shadow-md w-full h-full object-cover"
                  onerror="this.onerror=null; this.src='https://placehold.co/600x337/1e293b/ffffff?text=Project+6+LLM+Demo';"
                ></video>
              </div>
              <h4 class="text-xl font-bold text-sky-400 mb-2">
                6. Voice LLM on Jetson Orin
              </h4>
              <p class="text-slate-300 text-sm flex-grow">
                Development and deployment of a full, low-latency conversational
                AI pipeline—from Voice Activity Detection (VAD) to LLM
                inference—optimized specifically for the NVIDIA Jetson Orin edge
                platform.
              </p>
              <a
                href="product-voice-llm.html"
                class="text-sky-400 font-semibold text-sm mt-3 inline-block hover:underline"
                >Explore More &rarr;</a
              >
            </div>

            <!-- Project 7: SHIFTED - Visual Display of Annotated Objects (Original Project 4) -->
            <div class="content-card">
              <div class="responsive-media-container mb-4">
                <!-- YouTube Link for Project 4 (now 7) -->
                <iframe
                  width="100%"
                  height="100%"
                  src="https://www.youtube.com/embed/JE9Obtd2TlQ"
                  frameborder="0"
                  allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"
                  allowfullscreen
                  class="rounded-lg shadow-md"
                  title="Project 7 - Visual Display of Annotated Objects"
                ></iframe>
              </div>
              <h4 class="text-xl font-bold text-sky-400 mb-2">
                7. Visual Display of Annotated Objects using Unity and Cesium
                for Smart Urban Planning
              </h4>
              <p class="text-slate-300 text-sm flex-grow">
                Creating high-fidelity, interactive 3D visualizations of urban
                environments by rendering real-world annotated data over digital
                twins using the Unity Engine and Cesium 3D geospatial platform.
              </p>
              <a
                href="embedded_research.html"
                class="text-sky-400 font-semibold text-sm mt-3 inline-block hover:underline"
                >Explore Research &rarr;</a
              >
            </div>

            <!-- Project 8: SHIFTED - Satellite Image Annotator (Original Project 5) -->
            <div class="content-card">
              <div class="responsive-media-container mb-4">
                <!-- YouTube Link for Project 5 (now 8) -->
                <iframe
                  width="100%"
                  height="100%"
                  src="https://www.youtube.com/embed/v3gq_fhGSlE"
                  frameborder="0"
                  allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"
                  allowfullscreen
                  class="rounded-lg shadow-md"
                  title="Project 8 - Satellite Image Annotator"
                ></iframe>
              </div>
              <h4 class="text-xl font-bold text-sky-400 mb-2">
                8. Satellite Image Annotator
              </h4>
              <p class="text-slate-300 text-sm flex-grow">
                A specialized, web-based tool for efficiently labeling,
                segmenting, and classifying large-scale satellite and aerial
                imagery datasets to accelerate computer vision model training.
              </p>
              <a
                href="products.html"
                class="text-sky-400 font-semibold text-sm mt-3 inline-block hover:underline"
                >Explore Products &rarr;</a
              >
            </div>

            <!-- Project 9: SHIFTED - GPU Programming Learning Hub (Original Project 6) -->
            <div class="content-card">
              <div class="responsive-media-container mb-4">
                <!-- YouTube Link for Project 6 (now 9) -->
                <iframe
                  width="100%"
                  height="100%"
                  src="https://www.youtube.com/embed/hPXE96qSctc"
                  frameborder="0"
                  allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"
                  allowfullscreen
                  class="rounded-lg shadow-md"
                  title="Project 9 - GPU Programming Learning Hub"
                ></iframe>
              </div>
              <h4 class="text-xl font-bold text-sky-400 mb-2">
                9. GPU Programming Learning Hub
              </h4>
              <p class="text-slate-300 text-sm flex-grow">
                An open-source resource focused on advanced GPU programming
                techniques, covering topics like CUDA, OpenCL, Nsight profiling,
                and TensorRT for hardware-specific AI optimization.
              </p>
              <a
                href="ai_accelerated_hub.html"
                class="text-sky-400 font-semibold text-sm mt-3 inline-block hover:underline"
                >Go to Learning Hub &rarr;</a
              >
            </div>

            <!-- Project 10: SHIFTED - Smartpurchase as an AI assistant for retail (Original Project 7) -->
            <div class="content-card">
              <div class="responsive-media-container mb-4">
                <!-- YouTube Link for Project 7 (now 10) -->
                <iframe
                  width="100%"
                  height="100%"
                  src="https://www.youtube.com/embed/wqSR-2ARQZc"
                  frameborder="0"
                  allow="accelerometer; autoplay; clipboard-write; encrypted-picture"
                  allowfullscreen
                  class="rounded-lg shadow-md"
                  title="Project 10 - Smartpurchase AI Assistant"
                ></iframe>
              </div>
              <h4 class="text-xl font-bold text-sky-400 mb-2">
                10. Smartpurchase as an AI assistant for retail
              </h4>
              <p class="text-slate-300 text-sm flex-grow">
                An early full-stack prototype demonstrating how Computer Vision
                and Generative AI can transform the shopping experience.
                Features include personalized discounts, AI-driven shop
                management, and enhanced product exploration.
              </p>
              <a
                href="embedded_research.html"
                class="text-sky-400 font-semibold text-sm mt-3 inline-block hover:underline"
                >Explore Research &rarr;</a
              >
            </div>

            <!-- Project 11: SHIFTED - Multi-Barcode Detection (Real-time CV) (Original Project 8) -->
            <div class="content-card">
              <div class="responsive-media-container mb-4">
                <!-- Original Project 8 Video -->
                <video
                  src="shopping_ai_video.mp4"
                  autoplay
                  loop
                  muted
                  playsinline
                  class="rounded-lg shadow-md w-full h-full object-cover"
                  onerror="this.onerror=null; this.src='https://placehold.co/600x337/1e293b/ffffff?text=Project+11+Barcode+Video';"
                ></video>
              </div>
              <h4 class="text-xl font-bold text-sky-400 mb-2">
                11. Multi-Barcode Detection (Real-time CV)
              </h4>
              <p class="text-slate-300 text-sm flex-grow">
                Our AI quickly scans and identifies multiple products, forming
                the foundation of a rapid, intelligent checkout or inventory
                process for the retail environment.
              </p>
              <a
                href="product-virtual-sales-agent.html"
                class="text-sky-400 font-semibold text-sm mt-3 inline-block hover:underline"
                >Explore Use Case &rarr;</a
              >
            </div>

            <!-- Project 12: SHIFTED - AR Engagement Use Case (Original Project 9) -->
            <div class="content-card">
              <div class="responsive-media-container mb-4">
                <!-- Original Project 9 Video -->
                <video
                  src="ar_video.mp4"
                  autoplay
                  loop
                  muted
                  playsinline
                  class="rounded-lg shadow-md w-full h-full object-cover"
                  onerror="this.onerror=null; this.src='https://placehold.co/600x337/1e293b/ffffff?text=Project+12+AR+Video';"
                ></video>
              </div>
              <h4 class="text-xl font-bold text-sky-400 mb-2">
                12. AR Engagement Use Case
              </h4>
              <p class="text-slate-300 text-sm flex-grow">
                Engage customers with interactive Augmented Reality experiences,
                triggered by product recognition. This illustrates advanced
                multimodal interaction.
              </p>
              <a
                href="product-virtual-sales-agent.html"
                class="text-sky-400 font-semibold text-sm mt-3 inline-block hover:underline"
                >Explore Use Case &rarr;</a
              >
            </div>
          </div>
        </div>
      </section>

      <!-- Our Research Focus Section (no changes here) -->
      <section id="focus-areas" class="py-16">
        <div class="container mx-auto px-6">
          <h2 class="section-title text-sky-400">Our Research Focus</h2>
          <p class="section-subtitle">
            Targeting key technological pillars for the future of embedded and
            decentralized artificial intelligence.
          </p>

          <div class="grid md:grid-cols-2 lg:grid-cols-4 gap-8">
            <!-- Focus Area 1: Embedded AI Optimization -->
            <div class="content-card">
              <i class="fas fa-battery-half text-sky-400 text-4xl mb-4"></i>
              <h3 class="text-xl font-bold text-white mb-2">
                Embedded AI Optimization
              </h3>
              <p class="text-slate-300 text-sm">
                Developing highly efficient AI models for resource-constrained
                edge devices (ARM, RISC-V), ensuring maximum performance with
                minimal latency.
              </p>
            </div>

            <!-- Focus Area 2: Intelligent Robotics -->
            <div class="content-card">
              <i class="fas fa-cogs text-sky-400 text-4xl mb-4"></i>
              <h3 class="text-xl font-bold text-white mb-2">
                Intelligent Robotics
              </h3>
              <p class="text-slate-300 text-sm">
                Researching sensor fusion, real-time SLAM, and autonomous
                navigation algorithms for advanced robotic systems using
                platforms like Qualcomm and NVIDIA Jetson.
              </p>
            </div>

            <!-- Focus Area 3: Generative AI Applications -->
            <div class="content-card">
              <i class="fas fa-comments text-sky-400 text-4xl mb-4"></i>
              <h3 class="text-xl font-bold text-white mb-2">
                Generative AI Applications
              </h3>
              <p class="text-slate-300 text-sm">
                Exploring practical applications of LLMs and multimodal models
                in domains like commerce, education, and human-computer
                interaction.
              </p>
            </div>

            <!-- Focus Area 4: Accelerate Your Expertise (CTA) -->
            <div
              class="content-card bg-sky-900/50 border-sky-600 border-2 border-dashed flex flex-col justify-center items-center text-center p-6"
            >
              <h3 class="text-xl font-bold text-white mb-4">
                Accelerate Your Expertise
              </h3>
              <p class="text-slate-200 text-sm mb-6">
                Access our specialized technical trainings and open-source hub.
              </p>
              <div class="flex flex-col space-y-4 w-full">
                <a
                  href="embedded-ai-trainings.html"
                  class="cta-button cta-button-primary"
                >
                  View Specialized Trainings
                </a>
                <a
                  href="ai_accelerated_hub.html"
                  class="cta-button cta-button-secondary"
                >
                  Go to AI Accelerated Hub
                </a>
              </div>
            </div>
          </div>
        </div>
      </section>
    </main>

    <!-- Footer - VISITOR COUNTER ADDED HERE -->
    <footer class="bg-slate-900 border-t border-slate-800">
      <div
        class="container mx-auto px-6 py-4 text-center text-slate-400 flex flex-col sm:flex-row justify-between items-center"
      >
        <!-- Left Footer Content -->
        <div>
          <p class="text-sm mb-2 sm:mb-0">
            AI Fusion (Svaraikyam Research Lab) is an independent applied
            research initiative — not a commercial startup.
          </p>
          <p>
            &copy; 2025 Svaraikyam Research Lab (SRL). All Rights Reserved. |
            <a
              href="about-contact.html"
              class="hover:text-sky-400 transition-colors"
              >Contact</a
            >
          </p>
        </div>

        <!-- Visitor Counter Displays (UPDATED) -->
        <div
          class="mt-4 sm:mt-0 text-xs sm:text-sm flex flex-col space-y-2 sm:flex-row sm:space-x-4 sm:space-y-0"
        >
          <div
            class="flex items-center space-x-2 justify-center sm:justify-start"
          >
            <i class="fas fa-users text-sky-400"></i>
            <span class="font-semibold text-white">Total Unique Visitors:</span>
            <span id="visitor-counter" class="text-sky-400 font-bold text-lg"
              >0</span
            >
          </div>
           
            <span id="visitor-status" class="hidden"></span>
          </div>
        </div>
      </div>
    </footer>
  </body>
</html>
